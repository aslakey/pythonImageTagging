{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aslakey/anaconda3/lib/python3.4/site-packages/skimage/viewer/utils/core.py:11: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warnings.warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    }
   ],
   "source": [
    "#_______Consolidated Code for Project\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import resize\n",
    "#import cPickle\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.measure import regionprops\n",
    "from skimage import restoration\n",
    "from skimage import measure\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.viewer import ImageViewer\n",
    "from scipy.misc import toimage\n",
    "from skimage import feature\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read file into array as greyscale (need to eventually change to user uploaded image)\n",
    "filename = os.path.join(skimage.data_dir, 'quote_image.png') #change file name accordingly\n",
    "chk = io.imread(filename,as_grey = True) #returns greyscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process one Denoise and Increase Contrast\n",
    "image = restoration.denoise_tv_chambolle(chk, weight=0.1) #Denoises using total variation: http://scikit-image.org/docs/dev/api/skimage.restoration.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process two Finding Objects: http://scikit-image.org/docs/dev/auto_examples/plot_label.html\n",
    "#trying a canny filter to find edges http://www.danvk.org/2015/01/07/finding-blocks-of-text-in-an-image-using-python-opencv-and-numpy.html:\n",
    "edges = feature.canny(image, sigma=1) #a lower sigma shows more detail (2 is a happy medium)\n",
    "#this works well. Now segment the image based on edges using http://scikit-image.org/docs/dev/user_guide/tutorial_segmentation.html\n",
    "segmentation = ndi.binary_fill_holes(edges)\n",
    "labels, _ = ndi.label(segmentation)\n",
    "#toimage(labels).show()\n",
    "image_label_overlay = label2rgb(labels, image=chk)\n",
    "#toimage(image_label_overlay).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108, 284, 153, 302], [108, 336, 153, 354], [108, 440, 153, 457], [108, 528, 153, 546], [108, 716, 153, 734], [108, 768, 153, 785], [108, 821, 153, 838], [109, 192, 153, 212], [109, 215, 153, 230], [109, 305, 153, 323], [109, 355, 153, 377], [109, 409, 153, 428], [109, 460, 153, 480], [109, 482, 153, 503], [109, 548, 153, 564], [109, 575, 153, 594], [109, 596, 153, 616], [109, 618, 153, 634], [109, 646, 153, 664], [109, 667, 153, 675], [109, 677, 153, 695], [109, 697, 153, 714], [109, 736, 153, 755], [109, 758, 153, 765], [109, 841, 153, 858], [174, 510, 219, 528], [174, 580, 219, 598], [174, 651, 219, 669], [174, 721, 219, 739], [175, 231, 219, 251], [175, 253, 219, 273], [175, 275, 219, 292], [175, 332, 219, 339], [175, 366, 219, 384], [175, 432, 219, 454], [175, 455, 219, 475], [175, 476, 219, 486], [175, 490, 219, 508], [175, 530, 219, 549], [175, 601, 219, 619], [175, 622, 219, 640], [175, 670, 219, 692], [175, 693, 219, 700], [175, 704, 219, 719], [286, 376, 316, 388], [286, 411, 316, 425], [286, 427, 316, 439], [286, 457, 316, 470], [286, 472, 316, 484], [286, 510, 316, 523], [286, 526, 316, 538], [286, 540, 316, 552], [286, 607, 316, 619], [373, 426, 392, 446]]\n"
     ]
    }
   ],
   "source": [
    "#Process 3 Collect these regions filtering out small ones:\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "\n",
    "candidates = []\n",
    "for region in regionprops(labels):\n",
    "\n",
    "    # skip small images\n",
    "    if region.area < 200:\n",
    "        continue\n",
    "\n",
    "    # draw rectangle around each region\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    candidates.append([minr,minc,maxr,maxc])\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n",
    "print (candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process 4: decide if Region is a character or not!\n",
    "sample = candidates[3]\n",
    "max_x = sample[0]\n",
    "max_y=sample[1]\n",
    "min_x=sample[2]\n",
    "min_y=sample[3]\n",
    "toimage(image[max_x:min_x,max_y:min_y]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
